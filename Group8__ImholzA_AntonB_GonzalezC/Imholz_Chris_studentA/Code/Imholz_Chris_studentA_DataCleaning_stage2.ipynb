{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-22T22:25:37.042022300Z",
     "start_time": "2024-04-22T22:25:36.160980600Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "# Load the data file<\n",
    "file_path = '/home/student/Cloud/Owncloud/SyncVM/CIP/hslu-cip/Group8__ImholzA_AntonB_GonzalezC/Imholz_Chris_studentA/Data/Imholz_Chris_studentA_stage1.csv'\n",
    "#file_path = '/home/student/Cloud/Owncloud/SyncVM/CIP/hslu-cip/data/raw_data_stage1/Imholz_Chris_studentA_stage1.csv'\n",
    "data = pd.read_csv(file_path, delimiter=';')\n",
    "\n",
    "\n",
    "# Display the first few rows of the dataframe and the general information\n",
    "data.head()\n",
    "data.info()"
   ],
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/student/Cloud/Owncloud/SyncVM/CIP/hslu-cip/Group8__ImholzA_AntonB_GonzalezC/Imholz_Chris_studentA/Data/Imholz_Chris_studentA_stage1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[23], line 8\u001B[0m\n\u001B[0;32m      6\u001B[0m file_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/home/student/Cloud/Owncloud/SyncVM/CIP/hslu-cip/Group8__ImholzA_AntonB_GonzalezC/Imholz_Chris_studentA/Data/Imholz_Chris_studentA_stage1.csv\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m#file_path = '/home/student/Cloud/Owncloud/SyncVM/CIP/hslu-cip/data/raw_data_stage1/Imholz_Chris_studentA_stage1.csv'\u001B[39;00m\n\u001B[1;32m----> 8\u001B[0m data \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(file_path, delimiter\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m;\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     11\u001B[0m \u001B[38;5;66;03m# Display the first few rows of the dataframe and the general information\u001B[39;00m\n\u001B[0;32m     12\u001B[0m data\u001B[38;5;241m.\u001B[39mhead()\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:211\u001B[0m, in \u001B[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    209\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    210\u001B[0m         kwargs[new_arg_name] \u001B[38;5;241m=\u001B[39m new_arg_value\n\u001B[1;32m--> 211\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001B[0m, in \u001B[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    325\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m>\u001B[39m num_allow_args:\n\u001B[0;32m    326\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m    327\u001B[0m         msg\u001B[38;5;241m.\u001B[39mformat(arguments\u001B[38;5;241m=\u001B[39m_format_argument_list(allow_args)),\n\u001B[0;32m    328\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[0;32m    329\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39mfind_stack_level(),\n\u001B[0;32m    330\u001B[0m     )\n\u001B[1;32m--> 331\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001B[0m, in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[0;32m    935\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[0;32m    936\u001B[0m     dialect,\n\u001B[0;32m    937\u001B[0m     delimiter,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    946\u001B[0m     defaults\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdelimiter\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m},\n\u001B[0;32m    947\u001B[0m )\n\u001B[0;32m    948\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[1;32m--> 950\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001B[0m, in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    602\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[0;32m    604\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[1;32m--> 605\u001B[0m parser \u001B[38;5;241m=\u001B[39m TextFileReader(filepath_or_buffer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    607\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[0;32m    608\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[1;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[0;32m   1439\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m   1441\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1442\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_engine(f, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mengine)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[1;34m(self, f, engine)\u001B[0m\n\u001B[0;32m   1733\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[0;32m   1734\u001B[0m         mode \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m-> 1735\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m get_handle(\n\u001B[0;32m   1736\u001B[0m     f,\n\u001B[0;32m   1737\u001B[0m     mode,\n\u001B[0;32m   1738\u001B[0m     encoding\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[0;32m   1739\u001B[0m     compression\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcompression\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[0;32m   1740\u001B[0m     memory_map\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmemory_map\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m),\n\u001B[0;32m   1741\u001B[0m     is_text\u001B[38;5;241m=\u001B[39mis_text,\n\u001B[0;32m   1742\u001B[0m     errors\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mencoding_errors\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstrict\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m   1743\u001B[0m     storage_options\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstorage_options\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[0;32m   1744\u001B[0m )\n\u001B[0;32m   1745\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1746\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:856\u001B[0m, in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    851\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m    852\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[0;32m    853\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[0;32m    854\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[0;32m    855\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[1;32m--> 856\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(\n\u001B[0;32m    857\u001B[0m             handle,\n\u001B[0;32m    858\u001B[0m             ioargs\u001B[38;5;241m.\u001B[39mmode,\n\u001B[0;32m    859\u001B[0m             encoding\u001B[38;5;241m=\u001B[39mioargs\u001B[38;5;241m.\u001B[39mencoding,\n\u001B[0;32m    860\u001B[0m             errors\u001B[38;5;241m=\u001B[39merrors,\n\u001B[0;32m    861\u001B[0m             newline\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    862\u001B[0m         )\n\u001B[0;32m    863\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    864\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[0;32m    865\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/home/student/Cloud/Owncloud/SyncVM/CIP/hslu-cip/Group8__ImholzA_AntonB_GonzalezC/Imholz_Chris_studentA/Data/Imholz_Chris_studentA_stage1.csv'"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "source": [
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-22T22:25:37.030019500Z"
    }
   },
   "id": "3e28377be0663fc6",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Check for columns that are completely empty and drop them\n",
    "data_not_empty_columns = data.dropna(how='all', axis=1)\n",
    "\n",
    "# Show the columns removed (if any)\n",
    "data_not_empty_columns.columns.difference(data.columns)\n",
    "data=data_not_empty_columns\n",
    "\n",
    "# Updated DataFrame info\n",
    "data.info()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-22T22:25:37.032023600Z"
    }
   },
   "id": "bcda02f3606f84fb",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Count rows where all elements are NaN\n",
    "empty_rows_count = data.isna().all(axis=1).sum()\n",
    "print(\"Number of completely empty rows:\", empty_rows_count)\n",
    "\n",
    "# Check for rows that are completely empty and drop them\n",
    "data = data.dropna(how='all', axis=0)\n",
    "data\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-22T22:25:37.035020Z"
    }
   },
   "id": "2d2d34e4bbe41738",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Helper function to convert Market Cap to numeric\n",
    "# Beispiel-Wechselkurse zu USD: Google 18. Apr., 13:08 UTC\n",
    "exchange_rates = {\n",
    "'EUR': 1.07,\n",
    "'GBP': 1.25,\n",
    "'NOK': 0.091,\n",
    "'USD': 1\n",
    "}\n",
    "\n",
    "def expand_number(value):\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "    value = value.strip().upper()\n",
    "    if value.endswith('B'):\n",
    "        value =  float(value[:-1]) * 1e9  # Convert billions to a numeric value\n",
    "    elif value.endswith('M'):\n",
    "        value =  float(value[:-1]) * 1e6  # Convert millions to a numeric value\n",
    "    elif value.endswith('K'):\n",
    "        value =  float(value[:-1]) * 1e3  # Convert thousands to a numeric value\n",
    "    else:\n",
    "        value = float(value)  # Handle numeric-only strings as is\n",
    "    return round(value,3)\n",
    "\n",
    "def convert_to_usd(currency, amount):\n",
    "    if pd.isna(amount):\n",
    "        return np.nan\n",
    "    return amount * exchange_rates[currency]\n",
    "\n",
    "def process_market_cap(row):\n",
    "    # Erweitere den Betrag zu einer vollständigen Zahl\n",
    "    full_amount = expand_number(row['Market Cap'])\n",
    "    # Wandle die Währung in USD um\n",
    "    amount_in_usd = convert_to_usd(row['Currency'], full_amount)\n",
    "    return amount_in_usd\n",
    "\n",
    "# Lade den DataFrame, hier durch eine CSV-Datei ersetzt\n",
    "# data = pd.read_csv('path_to_your_csv.csv')\n",
    "\n",
    "# Annahme: 'data' ist ein DataFrame mit den Spalten 'Currency' und 'Market Cap'\n",
    "# Anwenden der Funktion\n",
    "data['Market Cap in USD'] = data.apply(process_market_cap, axis=1)\n",
    "data = data.drop('Market Cap',axis='columns')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-22T22:25:37.038019500Z"
    }
   },
   "id": "83b62884864c67f4",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def parse_and_convert_tons_currency(value):\n",
    "    # Prüft auf NaN Werte\n",
    "    if pd.isna(value) or value == '':\n",
    "        return None\n",
    "    \n",
    "    parts = value.split(' ')\n",
    "    \n",
    "    if len(parts) < 5:\n",
    "        return None\n",
    "\n",
    "    # Extrahiert den Betrag, die Einheit und die Währung\n",
    "    if parts[0].replace(',', '') == '':\n",
    "        return None\n",
    "    else:\n",
    "        amount = float(parts[0].replace(',', ''))\n",
    "    \n",
    "    unit = parts[2]\n",
    "    currency = parts[4].strip('()')\n",
    "\n",
    "    # Konvertiert Tausend in Millionen, falls nötig\n",
    "    if unit == 'Thousand':\n",
    "        amount /= 1000\n",
    "\n",
    "    # Wandelt den Betrag in USD um, falls er nicht bereits in USD ist\n",
    "    if currency != 'USD':\n",
    "        amount *= round(float(exchange_rates.get(currency,1)),3)\n",
    "\n",
    "    return amount\n",
    "\n",
    "# Anwendung der Funktion\n",
    "data['Carbon footprint (total GHG emissions / enterprise value)' + '_in_USD'] = data['Carbon footprint (total GHG emissions / enterprise value)'].apply(parse_and_convert_tons_currency)\n",
    "data = data.drop('Carbon footprint (total GHG emissions / enterprise value)',axis='columns')\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-22T22:25:37.039020300Z"
    }
   },
   "id": "57a5f4e444c28d44",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Helper function to convert percentage strings to floats\n",
    "def convert_percentage(value):\n",
    "    if pd.isna(value) or value.strip('% ') == '':\n",
    "        return np.nan\n",
    "    return round(float(value.strip('% ')) / 100,3)\n",
    "\n",
    "def unit_strip(value):\n",
    "    if pd.isna(value) or value.strip('unit') == '':\n",
    "        return np.nan\n",
    "    elif value.replace('unit', '') == \" \":\n",
    "        return np.nan\n",
    "    return float(value.replace('unit', ''))\n",
    "\n",
    "import re\n",
    "def convert_to_mwh(value):\n",
    "    conversion_factors = {\n",
    "    'GWh': 1000,\n",
    "    'terajoule': 277.778,\n",
    "    'gigajoule': 0.277778,\n",
    "    'MWh': 1\n",
    "    }\n",
    "    match = re.search(r'([\\d,]+(?:\\.\\d+)?)\\s*(GWh|MWh|terajoule|gigajoule)', str(value).replace(',', ''))\n",
    "    if match:\n",
    "        # Convert string value to float\n",
    "        value = float(match.group(1).replace(',', ''))\n",
    "        unit = match.group(2)\n",
    "        return round(value * conversion_factors[unit],3) # Convert the value to MWh\n",
    "\n",
    "# Apply conversions\n",
    "data['Share of women in total workforce in %'] = data['Share of women in total workforce'].apply(convert_percentage)\n",
    "data = data.drop(\"Share of women in total workforce\",axis='columns')\n",
    "data['Share of women in management bodies in %'] = data['Share of women in management bodies'].apply(convert_percentage)\n",
    "data = data.drop('Share of women in management bodies',axis='columns')\n",
    "data['Gender pay gap in %'] = data['Gender pay gap'].apply(convert_percentage)\n",
    "data = data.drop('Gender pay gap',axis='columns')\n",
    "data['Rate of employees with disabilities in %'] = data['Rate of employees with disabilities'].apply(convert_percentage)\n",
    "data = data.drop('Rate of employees with disabilities',axis='columns')\n",
    "data['Board gender diversity (female board members / total board members) in %'] = data['Board gender diversity (female board members / total board members)'].apply(convert_percentage)\n",
    "data = data.drop('Board gender diversity (female board members / total board members)',axis='columns')\n",
    "data['Professional equality index'] = data['Professional equality index'].apply(unit_strip)\n",
    "data['Number of female board members'] = data['Number of female board members'].apply(unit_strip)\n",
    "data['Number of board members'] = data['Number of board members'].apply(unit_strip)\n",
    "data['Average training hours per employee'] = data['Average training hours per employee'].apply(unit_strip)\n",
    "data['Total energy consumption in mwh'] = data['Total energy consumption'].apply(convert_to_mwh)\n",
    "data = data.drop('Total energy consumption', axis='columns')\n",
    "data['Rate of resignation in %'] = data['Rate of resignation'].apply(convert_percentage)\n",
    "data = data.drop('Rate of resignation', axis='columns')\n",
    "data\n",
    "\n",
    "# Transformed data\n",
    "data.head()\n",
    "data.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-22T22:25:37.041021800Z"
    }
   },
   "id": "9ac0d9a4f0c1187a",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T22:25:37.046018900Z",
     "start_time": "2024-04-22T22:25:37.044019900Z"
    }
   },
   "id": "50a7cbcbe0b65b8",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Calculate the percentage of missing values per column\n",
    "missing_data = data.isnull().mean() * 100.00\n",
    "\n",
    "# Display the percentage of missing data per column\n",
    "missing_data_sorted = missing_data.sort_values(ascending=False)\n",
    "missing_data_sorted\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-22T22:25:37.045019600Z"
    }
   },
   "id": "9cd3539ce15151dc",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Finden der Spalten, bei denen der Prozentsatz der fehlenden Daten größer als 80% ist\n",
    "columns_to_drop = missing_data[missing_data > 80].index\n",
    "# Löschen dieser Spalten aus dem DataFrame\n",
    "data.drop(columns=columns_to_drop, inplace=True)\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T22:25:37.051029300Z",
     "start_time": "2024-04-22T22:25:37.047019300Z"
    }
   },
   "id": "ad2f8ca609e45271",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "columns_to_drop"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-22T22:25:37.051029300Z"
    }
   },
   "id": "709c5966799b8bac",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "data.columns"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T22:25:37.054020500Z",
     "start_time": "2024-04-22T22:25:37.053022500Z"
    }
   },
   "id": "3c38e9590ccc7af5",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "#Save DataFrame to a CSV file with semicolon as the delimiter with the required _stage2.csv ending form project\n",
    "data.to_csv('/home/student/Cloud/Owncloud/SyncVM/CIP/hslu-cip/Group8__ImholzA_AntonB_GonzalezC/Imholz_Chris_studentA/Data/Imholz_Chris_studentA_stage3.csv', sep=';', index=False)\n",
    "# data.to_csv('/home/student/Cloud/Owncloud/SyncVM/CIP/hslu-cip/data/clean_data_stage3/Imholz_Chris_studentA_stage3.csv', sep=';', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T22:25:37.103551700Z",
     "start_time": "2024-04-22T22:25:37.056022600Z"
    }
   },
   "id": "c1d110da7bcfadc1",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# # Tabel erstellen \n",
    "# CREATE TABLE tbl_financial_euronext_data (\n",
    "#     id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "#     name VARCHAR(255),\n",
    "#     currency VARCHAR(255),\n",
    "#     market_cap_in_USD VARCHAR(255),\n",
    "#     carbon_footprint_total_GHG_emissions_per_enterprise_value VARCHAR(255),\n",
    "#     security_type VARCHAR(255),\n",
    "#     security_type_subtype VARCHAR(255),\n",
    "#     market VARCHAR(255),\n",
    "#     isin VARCHAR(20),\n",
    "#     industry VARCHAR(255),\n",
    "#     super_sector VARCHAR(255),\n",
    "#     sector VARCHAR(255),\n",
    "#     subsector VARCHAR(255),\n",
    "#     average_training_hours_per_employee VARCHAR(255),\n",
    "#     number_of_female_board_members VARCHAR(255),\n",
    "#     number_of_board_members VARCHAR(255),\n",
    "#     share_of_woman_in_total_workforce_in_percent VARCHAR(255),\n",
    "#     share_of_woman_in_management_bodies_in_percent VARCHAR(255),\n",
    "#     gender_pay_gap_in_percent VARCHAR(255),\n",
    "#     rate_of_employees_with_disabilities_in_percent VARCHAR(255),\n",
    "#     board_gender_diversity_in_percent VARCHAR(255),\n",
    "#     total_energy_consumption_in_mwh VARCHAR(255),\n",
    "#     rate_of_resignation_in_percent VARCHAR(255),\n",
    "# );"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-22T22:25:37.057021Z"
    }
   },
   "id": "67799f8f75840fee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-22T22:25:37.059545Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import mariadb\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "data = data.where(pd.notnull(data), '')\n",
    "# Verbindung zur Datenbank herstellen\n",
    "try:\n",
    "    conn = mariadb.connect(\n",
    "        user=\"cip_user\",\n",
    "        password=\"cip_pw\",\n",
    "        host=\"127.0.0.1\",\n",
    "        port=3306,\n",
    "        database=\"CIP\"\n",
    "    )\n",
    "except mariadb.Error as e:\n",
    "    print(f\"Error connecting to MariaDB Platform: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "conn.autocommit = False\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Daten in die Datenbank einfügen\n",
    "errors = []\n",
    "for index, row in data.iterrows():\n",
    "    query = \"\"\"\n",
    "    INSERT INTO tbl_financial_euronext_data\n",
    "    (name, currency, market_cap_in_USD, carbon_footprint_total_GHG_emissions_per_enterprise_value, security_type, security_type_subtype, market, isin, industry, super_sector, sector, subsector, average_training_hours_per_employee, number_of_female_board_members, number_of_board_members, share_of_woman_in_total_workforce_in_percent, share_of_woman_in_management_bodies_in_percent, gender_pay_gap_in_percent, rate_of_employees_with_disabilities_in_percent, board_gender_diversity_in_percent, total_energy_consumption_in_mwh, rate_of_resignation_in_percent) \n",
    "    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        cur.execute(query, (\n",
    "            row['Name'],\n",
    "            row['Currency'],\n",
    "            row['Market Cap in USD'],\n",
    "            row['Carbon footprint (total GHG emissions / enterprise value)_in_USD'],\n",
    "            row['Type'],\n",
    "            row['Sub type'],\n",
    "            row['Market'],\n",
    "            row['ISIN Code'],\n",
    "            row['Industry'],\n",
    "            row['SuperSector'],\n",
    "            row['Sector'],\n",
    "            row['Subsector'],\n",
    "            row['Average training hours per employee'],\n",
    "            row['Number of female board members'],\n",
    "            row['Number of board members'],\n",
    "            row['Share of women in total workforce in %'],\n",
    "            row['Share of women in management bodies in %'],\n",
    "            row['Gender pay gap in %'],\n",
    "            row['Rate of employees with disabilities in %'],\n",
    "            row['Board gender diversity (female board members / total board members) in %'],\n",
    "            row['Total energy consumption in mwh'],\n",
    "            row['Rate of resignation in %']\n",
    "        ))\n",
    "    except mariadb.Error as e:\n",
    "        errors.append(f\"Error: {e} at index {index}\")\n",
    "        continue\n",
    "\n",
    "# Änderungen bestätigen und Verbindung schließen\n",
    "conn.commit()\n",
    "\n",
    "\n",
    "# Fehler und Erfolgsmeldung ausgeben\n",
    "if errors:\n",
    "    print(f\"Es gab {len(errors)} Fehler beim Einfügen der Daten.\")\n",
    "for error in errors:\n",
    "    print(error)\n",
    "print(\"Data insertion complete.\")"
   ],
   "id": "9e3786627775d333",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-22T22:25:37.060544500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "try:\n",
    "    cur.execute(\"SELECT name FROM tbl_financial_euronext_data\")\n",
    "    for name in cur:\n",
    "        print(name)\n",
    "except mariadb.Error as e:\n",
    "    print(f\"Error: {e}\")"
   ],
   "id": "3518ec3c31293e6e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-22T22:25:37.061541800Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "conn.close()",
   "id": "645f07a84bb2c0f7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
